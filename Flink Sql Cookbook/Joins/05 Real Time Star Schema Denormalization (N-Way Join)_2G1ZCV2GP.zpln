{
  "paragraphs": [
    {
      "text": "%md\n\nIn this recipe, we will de-normalize a simple star schema with an n-way temporal table join. \t \n  \n[Star schemas](https://en.wikipedia.org/wiki/Star_schema) are a popular way of normalizing data within a data warehouse. At the center of a star schema is a **fact table** whose rows contain metrics, measurements, and other facts about the world. Surrounding fact tables are one or more **dimension tables** which have metadata useful for enriching facts when computing queries.  \nYou are running a small data warehouse for a railroad company which consists of a fact table (`train_activity`) and three dimension tables (`stations`, `booking_channels`, and `passengers`). All inserts to the fact table, and all updates to the dimension tables, are mirrored to Apache Kafka. Records in the fact table are interpreted as inserts only, and so the table is backed by the [standard Kafka connector](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/kafka.html) (`connector` \u003d `kafka`);. In contrast, the records in the dimensional tables are upserts based on a primary key, which requires the [Upsert Kafka connector](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/connectors/upsert-kafka.html) (`connector` \u003d `upsert-kafka`).\t \n\nWith Flink SQL you can now easily join all dimensions to our fact table using a 5-way temporal table join. Temporal table joins take an arbitrary table (left input/probe site) and correlate each row to the corresponding rowâ€™s relevant version in a versioned table (right input/build side). Flink uses the SQL syntax of ``FOR SYSTEM_TIME AS OF`` to perform this operation. Using a temporal table join leads to consistent, reproducible results when joining a fact table with more (slowly) changing dimensional tables. Every event (row in the fact table) is joined to its corresponding value of each dimension based on when the event occurred in the real world. \n",
      "user": "anonymous",
      "dateUpdated": "2021-02-27 15:18:59.166",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614305636615_1009654891",
      "id": "paragraph_1614305636615_1009654891",
      "dateCreated": "2021-02-26 10:13:56.615",
      "dateStarted": "2021-02-26 13:21:43.269",
      "dateFinished": "2021-02-26 13:21:43.317",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql\n\n\nDROP TABLE IF EXISTS passengers;\n\nCREATE TABLE passengers (\n  passenger_key STRING, \n  first_name STRING, \n  last_name STRING,\n  update_time TIMESTAMP(3),\n  WATERMARK FOR update_time AS update_time - INTERVAL \u002710\u0027 SECONDS,\n  PRIMARY KEY (passenger_key) NOT ENFORCED\n) WITH (\n  \u0027connector\u0027 \u003d \u0027upsert-kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027passengers\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027localhost:9092\u0027,\n  \u0027key.format\u0027 \u003d \u0027raw\u0027,\n  \u0027value.format\u0027 \u003d \u0027json\u0027\n);\n\nDROP TABLE IF EXISTS stations;\n\nCREATE TABLE stations (\n  station_key STRING, \n  update_time TIMESTAMP(3),\n  city STRING,\n  WATERMARK FOR update_time AS update_time - INTERVAL \u002710\u0027 SECONDS,\n  PRIMARY KEY (station_key) NOT ENFORCED\n) WITH (\n  \u0027connector\u0027 \u003d \u0027upsert-kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027stations\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027localhost:9092\u0027,\n  \u0027key.format\u0027 \u003d \u0027raw\u0027,\n  \u0027value.format\u0027 \u003d \u0027json\u0027\n);\n\nDROP TABLE IF EXISTS booking_channels;\n\nCREATE TABLE booking_channels (\n  booking_channel_key STRING, \n  update_time TIMESTAMP(3),\n  channel STRING,\n  WATERMARK FOR update_time AS update_time - INTERVAL \u002710\u0027 SECONDS,\n  PRIMARY KEY (booking_channel_key) NOT ENFORCED\n) WITH (\n  \u0027connector\u0027 \u003d \u0027upsert-kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027booking_channels\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027localhost:9092\u0027,\n  \u0027key.format\u0027 \u003d \u0027raw\u0027,\n  \u0027value.format\u0027 \u003d \u0027json\u0027\n);\n\nDROP TABLE IF EXISTS train_activities;\n\nCREATE TABLE train_activities (\n  scheduled_departure_time TIMESTAMP(3),\n  actual_departure_date TIMESTAMP(3),\n  passenger_key STRING, \n  origin_station_key STRING, \n  destination_station_key STRING,\n  booking_channel_key STRING,\n  WATERMARK FOR actual_departure_date AS actual_departure_date - INTERVAL \u002710\u0027 SECONDS\n) WITH (\n  \u0027connector\u0027 \u003d \u0027kafka\u0027,\n  \u0027topic\u0027 \u003d \u0027train_activities\u0027,\n  \u0027properties.bootstrap.servers\u0027 \u003d \u0027localhost:9092\u0027,\n  \u0027value.format\u0027 \u003d \u0027json\u0027,\n  \u0027value.fields-include\u0027 \u003d \u0027ALL\u0027\n);\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-27 15:20:14.742",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614316870006_1898527227",
      "id": "paragraph_1614316870006_1898527227",
      "dateCreated": "2021-02-26 13:21:10.006",
      "dateStarted": "2021-02-27 15:20:14.746",
      "dateFinished": "2021-02-27 15:20:15.750",
      "status": "FINISHED"
    },
    {
      "text": "%flink.ssql(type\u003dupdate)\n\nSELECT \n  t.actual_departure_date, \n  p.first_name,\n  p.last_name,\n  b.channel, \n  os.city AS origin_station,\n  ds.city AS destination_station\nFROM train_activities t\nLEFT JOIN booking_channels FOR SYSTEM_TIME AS OF t.actual_departure_date AS b \nON t.booking_channel_key \u003d b.booking_channel_key;\nLEFT JOIN passengers FOR SYSTEM_TIME AS OF t.actual_departure_date AS p\nON t.passenger_key \u003d p.passenger_key\nLEFT JOIN stations FOR SYSTEM_TIME AS OF t.actual_departure_date AS os\nON t.origin_station_key \u003d os.station_key\nLEFT JOIN stations FOR SYSTEM_TIME AS OF t.actual_departure_date AS ds\nON t.destination_station_key \u003d ds.station_key\nORDER BY t.actual_departure_date DESC\nLIMIT 10;\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-27 15:21:03.980",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614410414745_969940744",
      "id": "paragraph_1614410414745_969940744",
      "dateCreated": "2021-02-27 15:20:14.745",
      "dateStarted": "2021-02-27 15:21:03.984",
      "dateFinished": "2021-02-27 15:21:04.881",
      "status": "ERROR"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2021-02-27 15:20:55.778",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1614410455778_1166301104",
      "id": "paragraph_1614410455778_1166301104",
      "dateCreated": "2021-02-27 15:20:55.778",
      "status": "READY"
    }
  ],
  "name": "05 Real Time Star Schema Denormalization (N-Way Join)",
  "id": "2G1ZCV2GP",
  "defaultInterpreterGroup": "flink",
  "version": "0.10.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}